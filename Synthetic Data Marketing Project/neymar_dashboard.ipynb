{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84018934-3587-407a-8888-1f18651ee6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8054/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24e2e4acbc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# app.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import prince\n",
    "import plotly.express as px\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, dash_table\n",
    "from sklearn.cluster import KMeans\n",
    "# At top of app.py, import and configure a Kafka consumer\n",
    "from confluent_kafka import Consumer, TopicPartition\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "KAFKA_CONF = {\n",
    "    'bootstrap.servers':  'pkc-619z3.us-east1.gcp.confluent.cloud:9092',\n",
    "    'security.protocol':  'SASL_SSL',\n",
    "    'sasl.mechanisms':    'PLAIN',\n",
    "    'sasl.username':      'H7C5SHD4EUVIGHTZ',\n",
    "    'sasl.password':      'oyA7H99XPrK6c6I/aA3yB5fGhAlcp055Hr9ZdPrcqm5qlPRdsshfzS/Ku4xCHD8z',\n",
    "    'group.id':           'dash-live-group',\n",
    "    'auto.offset.reset':      'earliest',    # ← start from earliest\n",
    "    'enable.auto.commit':     False         # ← don’t commit offsets automatically\n",
    "}\n",
    "live_consumer = Consumer(KAFKA_CONF)\n",
    "live_consumer.subscribe(['watch_live_topic'])\n",
    "\n",
    "\n",
    "# ── 1) BigQuery client setup ────────────────────────────────────────────────\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"mindful-vial-460001-h6-4d83b36dd3e9.json\"\n",
    "KEY_PATH = \"mindful-vial-460001-h6-4d83b36dd3e9.json\"\n",
    "PROJECT  = \"mindful-vial-460001-h6\"\n",
    "CRED     = service_account.Credentials.from_service_account_file(KEY_PATH)\n",
    "client   = bigquery.Client(project=PROJECT, credentials=CRED)\n",
    "PROJECT = \"mindful-vial-460001-h6\"\n",
    "DATASET = \"euphoria\"\n",
    "client  = bigquery.Client(project=PROJECT)\n",
    "\n",
    "# ── 2) Shared queries & data ───────────────────────────────────────────────\n",
    "\n",
    "# Pre-load KPI data\n",
    "KPI_SQL = f\"\"\"\n",
    "WITH\n",
    "  viewed AS (\n",
    "    SELECT country, SUM(length) AS total_watch_seconds\n",
    "    FROM `{PROJECT}.{DATASET}.watch_topic`\n",
    "    GROUP BY country\n",
    "    ORDER BY total_watch_seconds DESC\n",
    "    LIMIT 10\n",
    "  ),\n",
    "  purchased AS (\n",
    "    SELECT product_name, COUNT(*) AS purchase_count\n",
    "    FROM `{PROJECT}.{DATASET}.purchase_events_topic`\n",
    "    GROUP BY product_name\n",
    "    ORDER BY purchase_count DESC\n",
    "    LIMIT 8\n",
    "  ),\n",
    "  streamer_perf AS (\n",
    "    SELECT\n",
    "      p.screen_name,\n",
    "      SUM((s.viewers_total/NULLIF(s.length,0)) * s.comments_total) AS performance_score\n",
    "    FROM `{PROJECT}.{DATASET}.streams_topic`   AS s\n",
    "    JOIN `{PROJECT}.{DATASET}.partners_topic`  AS p\n",
    "      ON s.partner_id = p.partner_id\n",
    "    GROUP BY p.screen_name\n",
    "    ORDER BY performance_score DESC\n",
    "    LIMIT 10\n",
    "  ),\n",
    "  best_games AS (\n",
    "    SELECT product_name, COUNT(*) AS purchase_count\n",
    "    FROM `{PROJECT}.{DATASET}.purchase_events_topic`\n",
    "    WHERE category = 'game'\n",
    "    GROUP BY product_name\n",
    "    ORDER BY purchase_count DESC\n",
    "    LIMIT 2\n",
    "  ),\n",
    "  streamed_games AS (\n",
    "    SELECT\n",
    "      g.title      AS game_title,\n",
    "      COUNT(*)     AS stream_count\n",
    "    FROM `{PROJECT}.{DATASET}.streams_topic` AS s\n",
    "    JOIN `{PROJECT}.{DATASET}.games_topic`   AS g\n",
    "      ON s.game_id = g.game_id\n",
    "    GROUP BY g.title\n",
    "    ORDER BY stream_count DESC\n",
    "    LIMIT 2\n",
    "  ),\n",
    "  top_cust_purch AS (\n",
    "    SELECT customer_id, COUNT(*) AS purchase_count\n",
    "    FROM `{PROJECT}.{DATASET}.purchase_events_topic`\n",
    "    GROUP BY customer_id\n",
    "    ORDER BY purchase_count DESC\n",
    "    LIMIT 1000\n",
    "  ),\n",
    "  top_cust_watch AS (\n",
    "    SELECT customer_id, SUM(length) AS total_watch_seconds\n",
    "    FROM `{PROJECT}.{DATASET}.watch_topic`\n",
    "    GROUP BY customer_id\n",
    "    ORDER BY total_watch_seconds DESC\n",
    "    LIMIT 1000\n",
    "  ),\n",
    "  monthly_watch AS (\n",
    "    SELECT\n",
    "      FORMAT('%04d-%02d',\n",
    "        EXTRACT(YEAR  FROM DATE(date)),\n",
    "        EXTRACT(MONTH FROM DATE(date))\n",
    "      ) AS period,\n",
    "      SUM(length) AS total_watch_seconds\n",
    "    FROM `{PROJECT}.{DATASET}.watch_topic`\n",
    "    GROUP BY period\n",
    "    ORDER BY period\n",
    "  ),\n",
    "  yearly_watch AS (\n",
    "    SELECT\n",
    "      CAST(EXTRACT(YEAR FROM DATE(date)) AS STRING) AS period,\n",
    "      SUM(length) AS total_watch_seconds\n",
    "    FROM `{PROJECT}.{DATASET}.watch_topic`\n",
    "    GROUP BY period\n",
    "    ORDER BY period\n",
    "  ),\n",
    "  monthly_merch AS (\n",
    "    SELECT\n",
    "      FORMAT('%04d-%02d',\n",
    "        EXTRACT(YEAR  FROM DATE(timestamp)),\n",
    "        EXTRACT(MONTH FROM DATE(timestamp))\n",
    "      ) AS period,\n",
    "      SUM(price) AS total_merch_sales\n",
    "    FROM `{PROJECT}.{DATASET}.purchase_events_topic`\n",
    "    WHERE category = 'merch'\n",
    "    GROUP BY period\n",
    "    ORDER BY period\n",
    "  ),\n",
    "  yearly_merch AS (\n",
    "    SELECT\n",
    "      CAST(EXTRACT(YEAR FROM DATE(timestamp)) AS STRING) AS period,\n",
    "      SUM(price) AS total_merch_sales\n",
    "    FROM `{PROJECT}.{DATASET}.purchase_events_topic`\n",
    "    WHERE category = 'merch'\n",
    "    GROUP BY period\n",
    "    ORDER BY period\n",
    "  )\n",
    "\n",
    "SELECT 'Top 10 Viewed Countries'       AS kpi, country        AS label, CAST(total_watch_seconds AS STRING)     AS value FROM viewed\n",
    "UNION ALL\n",
    "SELECT 'Top 8 Purchased Products'      AS kpi, product_name   AS label, CAST(purchase_count            AS STRING) AS value FROM purchased\n",
    "UNION ALL\n",
    "SELECT 'Top 10 Streamer Performance'   AS kpi, screen_name    AS label, CAST(ROUND(performance_score,2) AS STRING) AS value FROM streamer_perf\n",
    "UNION ALL\n",
    "SELECT 'Top 2 Best-Selling Games'      AS kpi, product_name   AS label, CAST(purchase_count            AS STRING) AS value FROM best_games\n",
    "UNION ALL\n",
    "SELECT 'Top 2 Most-Streamed Games'     AS kpi, game_title     AS label, CAST(stream_count              AS STRING) AS value FROM streamed_games\n",
    "UNION ALL\n",
    "SELECT 'Top 1000 Customers by Purchases'      AS kpi, customer_id AS label, CAST(purchase_count            AS STRING) AS value FROM top_cust_purch\n",
    "UNION ALL\n",
    "SELECT 'Top 1000 Customers by Watch Seconds'  AS kpi, customer_id AS label, CAST(total_watch_seconds       AS STRING) AS value FROM top_cust_watch\n",
    "UNION ALL\n",
    "SELECT 'Monthly Watch (sec)'           AS kpi, period         AS label, CAST(total_watch_seconds       AS STRING) AS value FROM monthly_watch\n",
    "UNION ALL\n",
    "SELECT 'Yearly Watch (sec)'            AS kpi, period         AS label, CAST(total_watch_seconds       AS STRING) AS value FROM yearly_watch\n",
    "UNION ALL\n",
    "SELECT 'Monthly Merch Sales'           AS kpi, period         AS label, FORMAT('$%.2f', total_merch_sales)        AS value FROM monthly_merch\n",
    "UNION ALL\n",
    "SELECT 'Yearly Merch Sales'            AS kpi, period         AS label, FORMAT('$%.2f', total_merch_sales)        AS value FROM yearly_merch\n",
    ";\n",
    "\"\"\"\n",
    "df_kpi = client.query(KPI_SQL).to_dataframe()\n",
    "\n",
    "# ── 3) Trophy segmentation util ────────────────────────────────────────────\n",
    "def compute_trophy_segments(sample_limit=50000, k=4):\n",
    "    sql = f\"\"\"\n",
    "      WITH trophy_profiles AS (\n",
    "        SELECT\n",
    "          c.customer_id,\n",
    "          DATE_DIFF(CURRENT_DATE(), DATE(c.birthday), YEAR) AS age,\n",
    "          c.gender,\n",
    "          c.region\n",
    "        FROM `{PROJECT}.{DATASET}.purchase_events_topic` p\n",
    "        JOIN `{PROJECT}.{DATASET}.customers_topic` c\n",
    "          USING(customer_id)\n",
    "        WHERE p.category='merch'\n",
    "          AND p.product_name='Authentic Mahiman Trophy'\n",
    "      )\n",
    "      SELECT *\n",
    "      FROM trophy_profiles\n",
    "      LIMIT {sample_limit}\n",
    "    \"\"\"\n",
    "    df = client.query(sql).to_dataframe()\n",
    "    # bin age\n",
    "    df['age_bin'] = pd.cut(\n",
    "      df['age'], bins=range(10,81,5),\n",
    "      labels=[f\"{i}-{i+4}\" for i in range(10,80,5)],\n",
    "      right=False\n",
    "    )\n",
    "    # MCA\n",
    "    df_mca = df[['age_bin','gender','region']].astype(str)\n",
    "    mca = prince.MCA(n_components=2, engine='sklearn', random_state=42).fit(df_mca)\n",
    "    coords = mca.transform(df_mca)\n",
    "    coords.columns = ['Dim1','Dim2']\n",
    "    # KMeans\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    coords['cluster'] = km.fit_predict(coords[['Dim1','Dim2']])\n",
    "    df['cluster']     = coords['cluster']\n",
    "    # summary\n",
    "    summary = pd.DataFrame([\n",
    "      {\n",
    "        'cluster': i,\n",
    "        'size': int((df.cluster==i).sum()),\n",
    "        'top_regions': df[df.cluster==i].region.value_counts().head(5).to_dict(),\n",
    "        'avg_age': df[df.cluster==i].age.mean()\n",
    "      }\n",
    "      for i in range(k)\n",
    "    ])\n",
    "    return coords, df, summary, km.cluster_centers_\n",
    "\n",
    "coords_seg, df_seg, df_seg_summary, seg_centers = compute_trophy_segments()\n",
    "\n",
    "\n",
    "# ── 4) Build Dash app ────────────────────────────────────────────────\n",
    "app = dash.Dash(__name__, suppress_callback_exceptions=True)\n",
    "app.title = \"Euphoria Analytical Dashboard\"\n",
    "\n",
    "app.layout = html.Div([\n",
    "  dcc.Tabs([\n",
    "    dcc.Tab(label=\"SQL Runner\", children=[\n",
    "      html.H3(\"BigQuery SQL Runner\"),\n",
    "      dcc.Textarea(\n",
    "        id='sql-input',\n",
    "        value=f\"SELECT * FROM `{PROJECT}.{DATASET}.streams_topic` LIMIT 5;\",\n",
    "        style={'width':'100%','height':'120px'}\n",
    "      ),\n",
    "      html.Button(\"Run Query\", id='run-sql'),\n",
    "      html.Div(id='sql-table')\n",
    "    ]),\n",
    "    dcc.Tab(label=\"Live Watch (5m)\", children=[\n",
    "      html.H3(\"Live Watch Hours (last 5 min)\"),\n",
    "      dcc.Graph(id='live-choropleth'),\n",
    "      dcc.Interval(id='interval-live', interval=10*1000, disabled=False)\n",
    "    ]),\n",
    "    dcc.Tab(label=\"KPI Dashboard\", children=[\n",
    "      html.H3(\"Euphoria KPIs\"),\n",
    "      dcc.Dropdown(\n",
    "        id='kpi-dropdown',\n",
    "        options=[{'label': k, 'value': k} for k in df_kpi.kpi.unique()],\n",
    "        value=df_kpi.kpi.unique()[0]\n",
    "      ),\n",
    "      dash_table.DataTable(\n",
    "        id='kpi-table',\n",
    "        columns=[{'name':c,'id':c} for c in df_kpi.columns],\n",
    "        page_size=10\n",
    "      )\n",
    "    ]),\n",
    "    dcc.Tab(label=\"Yearly Watch Rank\", children=[\n",
    "      html.H3(\"Yearly Relative Watch Hours\"),\n",
    "      dcc.Dropdown(\n",
    "        id='year-dropdown',\n",
    "        options=[{'label':y,'value':y} for y in range(pd.Timestamp.now().year, pd.Timestamp.now().year-10, -1)],\n",
    "        value=pd.Timestamp.now().year\n",
    "      ),\n",
    "      dcc.Graph(id='yearly-choropleth')\n",
    "    ]),\n",
    "    dcc.Tab(label=\"Trophy Segments\", children=[\n",
    "      html.H3(\"Trophy Buyer Segments (MCA + KMeans)\"),\n",
    "      dash_table.DataTable(\n",
    "        id='seg-summary',\n",
    "        columns=[{'name':c,'id':c} for c in df_seg_summary.columns],\n",
    "        data=df_seg_summary.to_dict('records')\n",
    "      ),\n",
    "      dcc.Graph(id='seg-scatter')\n",
    "    ])\n",
    "  ])\n",
    "], style={'padding':'20px'})\n",
    "\n",
    "# ── 5) Callbacks ─────────────────────────────────────────────────────────\n",
    "\n",
    "# SQL Runner\n",
    "@app.callback(\n",
    "  Output('sql-table','children'),\n",
    "  Input('run-sql','n_clicks'),\n",
    "  Input('sql-input','value')\n",
    ")\n",
    "def run_sql(n, query):\n",
    "  if not n: return html.Div(\"Click Run Query\")\n",
    "  q = re.sub(r\"\\bPROJECT\\b\", PROJECT, query)\n",
    "  q = re.sub(r\"\\bDATASET\\b\", DATASET, q)\n",
    "  df = client.query(q).to_dataframe()\n",
    "  return dash_table.DataTable(\n",
    "    columns=[{'name':c,'id':c} for c in df.columns],\n",
    "    data=df.to_dict('records'),\n",
    "    page_size=10\n",
    "  )\n",
    "\n",
    "# Live watch map\n",
    "# ── Live watch map (15% real-time substream) ───────────────────────────────\n",
    "# Replace your update_live callback with this:\n",
    "@app.callback(\n",
    "    Output('live-choropleth', 'figure'),\n",
    "    Input('interval-live', 'n_intervals')\n",
    ")\n",
    "def update_live(n):\n",
    "    # 1) Reset to beginning of each partition\n",
    "    for tp in live_consumer.assignment():\n",
    "        tp = TopicPartition(tp.topic, tp.partition, 0)\n",
    "        live_consumer.seek(tp)\n",
    "\n",
    "    # 2) Consume messages\n",
    "    msgs = live_consumer.consume(num_messages=200, timeout=1.0)\n",
    "    records = []\n",
    "    cutoff  = datetime.now(timezone.utc) - timedelta(minutes=5)\n",
    "\n",
    "    for msg in msgs or []:\n",
    "        if msg is None or msg.error():\n",
    "            continue\n",
    "        rec = json.loads(msg.value().decode('utf-8'))\n",
    "        ts  = datetime.fromisoformat(rec['date'].replace('Z','+00:00'))\n",
    "        if ts >= cutoff:\n",
    "            records.append(rec)\n",
    "\n",
    "    # 3) Empty‐data fallback\n",
    "    if not records:\n",
    "        empty = pd.DataFrame({'country':[], 'watch_hours':[]})\n",
    "        fig = px.choropleth(\n",
    "            empty, locations='country', locationmode='country names',\n",
    "            color='watch_hours', color_continuous_scale='Viridis'\n",
    "        )\n",
    "        fig.update_layout(title=\"No live watch data in the past 5 minutes\")\n",
    "        return fig\n",
    "\n",
    "    # 4) Aggregate and plot\n",
    "    df_live = pd.DataFrame(records)\n",
    "    agg     = df_live.groupby('country', as_index=False)['length'].sum()\n",
    "    agg['watch_hours'] = agg['length'] / 3600.0\n",
    "\n",
    "    fig = px.choropleth(\n",
    "        agg,\n",
    "        locations='country',\n",
    "        locationmode='country names',\n",
    "        color='watch_hours',\n",
    "        hover_name='country',\n",
    "        color_continuous_scale='Viridis',\n",
    "        range_color=(0, agg.watch_hours.max())\n",
    "    )\n",
    "    fig.update_layout(title=\"Live Watch Hours (last 5 min)\")\n",
    "    return fig\n",
    "\n",
    "# KPI table\n",
    "@app.callback(\n",
    "  Output('kpi-table','data'),\n",
    "  Input('kpi-dropdown','value')\n",
    ")\n",
    "def update_kpi(k):\n",
    "  return df_kpi[df_kpi.kpi==k].to_dict('records')\n",
    "\n",
    "# Yearly watch rank\n",
    "@app.callback(\n",
    "  Output('yearly-choropleth','figure'),\n",
    "  Input('year-dropdown','value')\n",
    ")\n",
    "def update_year(y):\n",
    "  sql = f\"\"\"\n",
    "    WITH country_totals AS (\n",
    "      SELECT country, SUM(length)/3600.0 AS watch_hours\n",
    "      FROM `{PROJECT}.{DATASET}.watch_topic`\n",
    "      WHERE EXTRACT(YEAR FROM DATE(date)) = {y}\n",
    "      GROUP BY country\n",
    "    )\n",
    "    SELECT country, watch_hours,\n",
    "      PERCENT_RANK() OVER (ORDER BY watch_hours) AS pct_rank\n",
    "    FROM country_totals\n",
    "  \"\"\"\n",
    "  df = client.query(sql).to_dataframe()\n",
    "  return px.choropleth(\n",
    "    df, locations='country', locationmode='country names',\n",
    "    color='pct_rank', hover_name='country',\n",
    "    hover_data={'watch_hours':':.1f','pct_rank':':.2f'},\n",
    "    color_continuous_scale='Viridis', range_color=(0,1)\n",
    "  )\n",
    "\n",
    "# Trophy segments scatter\n",
    "@app.callback(\n",
    "    Output('seg-scatter','figure'),\n",
    "    Input('seg-summary','data')\n",
    ")\n",
    "def update_seg(_):\n",
    "    fig = px.scatter(\n",
    "        coords_seg, x='Dim1', y='Dim2',\n",
    "        color='cluster', title='Trophy Buyer Segments'\n",
    "    )\n",
    "    # plot the returned centers\n",
    "    fig.add_scatter(\n",
    "        x=seg_centers[:,0],\n",
    "        y=seg_centers[:,1],\n",
    "        mode='markers',\n",
    "        marker=dict(symbol='x', size=12, color='black'),\n",
    "        name='Centroids'\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "# ── 6) Run server ─────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True,port=8054)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8632db3-583c-4e49-bfcb-21594b30c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
